# Curso-Ebac-Analista-de-dados
Este repositório contém os exercícios e projetos desenvolvidos durante o curso "Profissão: Analista de Dados v2" da EBAC - Escola Britânica de Artes Criativas e Tecnologia. O curso abrange os principais conceitos e técnicas necessários para se tornar um analista de dados, incluindo a manipulação e análise de dados, visualização de informações e construção de modelos preditivos.

**Estrutura do Repositório**
O repositório está organizado da seguinte forma:

**- Projetos/:** Nesta pasta, você encontrará os projetos desenvolvidos ao longo do curso. Cada projeto possui uma pasta dedicada, contendo os arquivos e as instruções necessárias para executá-lo.

**- Exercicios/:** Esta pasta contém os exercícios práticos realizados durante o curso. Cada exercício está separado em pastas individuais, com uma breve descrição e os arquivos relacionados.
## Lista de Projetos
Aqui está uma lista dos projetos desenvolvidos durante o curso:

**Projeto 1: Análise Exploratória de Dados de Logística (Loggi)**
Neste projeto, mergulhamos profundamente nos dados de uma empresa de logística real. Desde a coleta e limpeza dos dados até a criação de visualizações perspicazes e descoberta de insights valiosos, este projeto demonstra minha capacidade de trabalhar com dados complexos em um cenário do mundo real. Um destaque deste projeto é o uso da API de geocodificação Nominatim para enriquecer nossos dados com informações geográficas.

**Projeto 2: Análise de Dados Interativa COVID-19 Dashboard**
Este projeto apresenta uma análise aprofundada do impacto da pandemia de COVID-19 durante o período de 2020 a 2022 em quatro países - Brasil, Alemanha, Índia e Estados Unidos. Utilizamos indicadores como o Índice de Desenvolvimento Humano (IDH) e o Produto Interno Bruto com paridade de Poder de Compra (PPC) para contextualizar os efeitos da pandemia. Além da análise realizada no Jupyter Notebook, também criamos um painel de visualização interativo na plataforma Looker Studio.


**Projeto 3: Data Pipeline | AWS - Whatsapp - Telegram**
Desenvolvimento de um pipeline de dados utilizando os serviços em nuvem da AWS, incorporando um processo ETL para extrair dados do Telegram e WhatsApp por meio de APIs. Os dados são então transferidos para um Datalake e processados em lote na nuvem de acordo com uma agenda, proporcionando as informações prontas para a análise.
